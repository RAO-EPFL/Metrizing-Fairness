{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        \n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            loss = self.accloss(y_hat, self.y) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)\n",
    "\n",
    "class TrainerDebiased:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            y_1 = self.y[self.a==1]\n",
    "            y_0 = self.y[self.a==0]\n",
    "            delta_1, delta_0 = 1, 1\n",
    "            N = len(self.a)\n",
    "            N_1 = self.a.sum()\n",
    "            N_0 = N-N_1\n",
    "            if N >= self.N:\n",
    "                if N_1 == 2:\n",
    "                    delta_1 = N/(2*(N-1))\n",
    "                    delta_0 = N/((N-1))\n",
    "                else:\n",
    "                    delta_1 = N/((N-1))\n",
    "                    delta_0 = N/(2*(N-1))\n",
    "            weight_1 = (delta_1) * N_1/N\n",
    "            weight_0 = (delta_0) * N_0/N\n",
    "            accloss1 = self.accloss(y_hat_1, y_1)\n",
    "            accloss0 = self.accloss(y_hat_0, y_0)\n",
    "            loss = (weight_0 * accloss0 + weight_1 * accloss1) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, X, y1, y2, a, metrics):\n",
    "        self.X = X\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.a = a\n",
    "        \n",
    "        self.metrics = metrics\n",
    "        self.results = {k:[] for k in metrics.keys()}\n",
    "        self.MSEs = []\n",
    "        \n",
    "    def test(self, model, regime):\n",
    "        y = self.y1 if regime==1 else self.y2\n",
    "        y_hat = model(self.X)\n",
    "        MSE = ((y.flatten()-y_hat.flatten())**2).mean()\n",
    "        self.MSEs.append(MSE.detach().numpy()[()])\n",
    "        \n",
    "        \n",
    "        y_hat_1 = y_hat[self.a==1]\n",
    "        y_hat_0 = y_hat[self.a==0]\n",
    "        for m in self.metrics.keys():\n",
    "            self.results[m].append(self.metrics[m](y_hat_1, y_hat_0).detach().numpy()[()])\n",
    "        \n",
    "    def __call__(self, model, regime):\n",
    "        self.test(model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "N_iter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes1 = 4*torch.rand((k, 5))-2\n",
    "slopes2 = 4*torch.rand((k, 5))-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(k, regime):\n",
    "    X = torch.rand((1,k-1))\n",
    "    a = torch.randint(2,(1,))\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max()\n",
    "    y2 = (X @ slopes2).max()\n",
    "    if regime==1:\n",
    "        return X, y1, a\n",
    "    else:\n",
    "        return X, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_set(k, N_test=1000):\n",
    "    X = torch.rand((N_test,k-1))\n",
    "    a = torch.randint(2,(N_test,))\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max(dim=1)[0]\n",
    "    y2 = (X @ slopes2).max(dim=1)[0]\n",
    "    return X, y1, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(k, 20, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(20, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        self.output = self.linear2(x)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, y):\n",
    "    return ((yhat.flatten()-y.flatten())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'SPD': lambda y1, y2: fairness_metrics.statistical_parity(y1.flatten(), y2.flatten(), None, None),\n",
    "    'ED': fairness_metrics.energy_distance,\n",
    "    'WD': fairness_metrics.wasserstein_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(N=4, seed=0):\n",
    "    test_set = build_test_set(k)\n",
    "    tester_ED = Tester(*test_set, metrics)\n",
    "    tester_ED_db = Tester(*test_set, metrics)\n",
    "    tester_WD = Tester(*test_set, metrics)\n",
    "    tester_WD_bign = Tester(*test_set, metrics)\n",
    "    tester_ED_bign = Tester(*test_set, metrics)\n",
    "    tester_ED_db_bign = Tester(*test_set, metrics)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance, N, [2,2], tester_ED)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_db = TrainerDebiased(NeuralNetwork(k), mse, fairness_metrics.energy_distance, N, [2,2], tester_ED_db)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_bigN = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance, 50, [2,2], tester_ED_bign)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_db_bigN = TrainerDebiased(NeuralNetwork(k), mse, fairness_metrics.energy_distance, 50, [2,2], tester_ED_db_bign)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_WD = Trainer(NeuralNetwork(k), mse, fairness_metrics.wasserstein_distance, N, [2,2], tester_WD)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_WD_bigN = Trainer(NeuralNetwork(k), mse, fairness_metrics.wasserstein_distance, 50, [2,2], tester_WD_bign)\n",
    "    regime = 1\n",
    "    for i in tqdm(range(N_iter)):\n",
    "        sample = get_sample(k, regime)\n",
    "        trainer_ED.update(*sample, regime)\n",
    "        trainer_ED_db.update(*sample, regime)\n",
    "        trainer_WD.update(*sample, regime)\n",
    "        trainer_WD_bigN.update(*sample, regime)\n",
    "        trainer_ED_bigN.update(*sample, regime)\n",
    "        trainer_ED_db_bigN.update(*sample, regime)\n",
    "        if i==N_iter/2:\n",
    "            regime = 2\n",
    "\n",
    "    return (trainer_ED.tester, trainer_WD.tester, trainer_WD_bigN.tester, trainer_ED_bigN.tester, trainer_ED_db.tester, trainer_ED_db_bigN.tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "EDs, WDs,WD_bigNs, ED_bigNs = [],[],[], []\n",
    "dbs, dbbigns = [],[]\n",
    "for i in range(5):\n",
    "    ED, WD, WD_bigN, ED_bigN, db, dbbign = test(seed = i)\n",
    "    EDs.append(ED)\n",
    "    WDs.append(WD)\n",
    "    WD_bigNs.append(WD_bigN)\n",
    "    ED_bigNs.append(ED_bigN)\n",
    "    dbs.append(db)\n",
    "    dbbigns.append(dbbign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.sans-serif'] = ['Times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dumps/slope1.npy', slopes1.numpy())\n",
    "np.save('dumps/slope2.npy', slopes2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in dbs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='ED (N=4)')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in dbbigns]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='ED (N=50)')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['WD']) for tester in WDs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='WD (N=4)')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['WD']) for tester in WD_bigNs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='WD (N=50)')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.savefig('loss-comparison.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in EDs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='ED (Biased)')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in dbs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='ED (Debiased)')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.savefig('loss-comparison-bias.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-aaron",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
