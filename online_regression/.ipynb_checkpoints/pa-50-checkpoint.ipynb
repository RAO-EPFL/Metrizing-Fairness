{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuck-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "headed-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        \n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            loss = self.accloss(y_hat, self.y) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)\n",
    "\n",
    "class TrainerDebiased:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            y_1 = self.y[self.a==1]\n",
    "            y_0 = self.y[self.a==0]\n",
    "            delta_1, delta_0 = 1, 1\n",
    "            N = len(self.a)\n",
    "            N_1 = self.a.sum()\n",
    "            N_0 = N-N_1\n",
    "            if N >= self.N:\n",
    "                if N_1 == 2:\n",
    "                    delta_1 = N/(2*(N-1))\n",
    "                    delta_0 = N/((N-1))\n",
    "                else:\n",
    "                    delta_1 = N/((N-1))\n",
    "                    delta_0 = N/(2*(N-1))\n",
    "            weight_1 = (delta_1) * N_1/N\n",
    "            weight_0 = (delta_0) * N_0/N\n",
    "            accloss1 = self.accloss(y_hat_1, y_1)\n",
    "            accloss0 = self.accloss(y_hat_0, y_0)\n",
    "            loss = (weight_0 * accloss0 + weight_1 * accloss1) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intense-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, X, y1, y2, a, metrics):\n",
    "        self.X = X\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.a = a\n",
    "        \n",
    "        self.metrics = metrics\n",
    "        self.results = {k:[] for k in metrics.keys()}\n",
    "        self.MSEs = []\n",
    "        \n",
    "    def test(self, model, regime):\n",
    "        y = self.y1 if regime==1 else self.y2\n",
    "        y_hat = model(self.X)\n",
    "        MSE = ((y.flatten()-y_hat.flatten())**2).mean()\n",
    "        self.MSEs.append(MSE.detach().numpy()[()])\n",
    "        \n",
    "        \n",
    "        y_hat_1 = y_hat[self.a==1]\n",
    "        y_hat_0 = y_hat[self.a==0]\n",
    "        for m in self.metrics.keys():\n",
    "            self.results[m].append(self.metrics[m](y_hat_1, y_hat_0).detach().numpy()[()])\n",
    "        \n",
    "    def __call__(self, model, regime):\n",
    "        self.test(model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boolean-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "N_iter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hourly-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1909babedd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "computational-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes1 = 4*torch.rand((k, 5))-2\n",
    "slopes2 = 4*torch.rand((k, 5))-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lined-winter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randint(10,(1,))==0).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "billion-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_inverse=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rental-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(k, regime):\n",
    "    X = torch.rand((1,k-1))\n",
    "    a = (torch.randint(pa_inverse,(1,))==0).float()\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max()\n",
    "    y2 = (X @ slopes2).max()\n",
    "    if regime==1:\n",
    "        return X, y1, a\n",
    "    else:\n",
    "        return X, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minus-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_set(k, N_test=1000):\n",
    "    X = torch.rand((N_test,k-1))\n",
    "    a = (torch.randint(pa_inverse,(N_test,))==0).float()\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max(dim=1)[0]\n",
    "    y2 = (X @ slopes2).max(dim=1)[0]\n",
    "    return X, y1, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recovered-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(k, 20, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(20, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        self.output = self.linear2(x)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opening-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, y):\n",
    "    return ((yhat.flatten()-y.flatten())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "statistical-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'SPD': lambda y1, y2: fairness_metrics.statistical_parity(y1.flatten(), y2.flatten(), None, None),\n",
    "    'ED': fairness_metrics.energy_distance,\n",
    "    'WD': fairness_metrics.wasserstein_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rotary-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(N=4, seed=0):\n",
    "    test_set = build_test_set(k)\n",
    "    tester_ED = Tester(*test_set, metrics)\n",
    "    tester_ED_db = Tester(*test_set, metrics)\n",
    "    tester_ED_fullbias = Tester(*test_set, metrics)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance, N, [2,2], tester_ED)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_db = TrainerDebiased(NeuralNetwork(k), mse, fairness_metrics.energy_distance, N, [2,2], tester_ED_db)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_fullbias = TrainerDebiased(NeuralNetwork(k), mse, fairness_metrics.energy_distance_biased, N, [2,2], tester_ED_fullbias)\n",
    "    \n",
    "    regime = 1\n",
    "    for i in tqdm(range(N_iter)):\n",
    "        sample = get_sample(k, regime)\n",
    "        trainer_ED.update(*sample, regime)\n",
    "        trainer_ED_db.update(*sample, regime)\n",
    "        trainer_ED_fullbias.update(*sample, regime)\n",
    "        if i==N_iter/2:\n",
    "            regime = 2\n",
    "\n",
    "    return (trainer_ED.tester, trainer_ED_db.tester, trainer_ED_fullbias.tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [09:09<00:00,  7.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4000/4000 [09:01<00:00,  7.38it/s]\n",
      " 46%|███████████████████████████████████▋                                          | 1831/4000 [04:18<05:00,  7.22it/s]"
     ]
    }
   ],
   "source": [
    "EDs, dbs, fullbiases = [],[],[]\n",
    "dbs, dbbigns = [],[]\n",
    "for i in range(5):\n",
    "    ED, db, fullbias = test(seed = i)\n",
    "    EDs.append(ED)\n",
    "    dbs.append(db)\n",
    "    fullbiases.append(fullbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.sans-serif'] = ['Times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dumps/slope1.npy', slopes1.numpy())\n",
    "np.save('dumps/slope2.npy', slopes2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in EDs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Debiased ED')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in dbs]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Full Debias')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in fullbiases]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Biased Loss and ED')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "#plt.savefig('loss-comparison-bias.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
