{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374e54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        \n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            loss = self.accloss(y_hat, self.y) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)\n",
    "\n",
    "class TrainerDebiased:\n",
    "    def __init__(self, model, accloss, fairloss, N, Na, tester, regularizer=2, lr=1e-2):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.accloss = accloss\n",
    "        self.fairloss = fairloss\n",
    "        self.tester = tester\n",
    "        self.N = N\n",
    "        self.Na = Na\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.a = None\n",
    "        self.regularizer = regularizer\n",
    "        self.tester(self.model, 1)\n",
    "    \n",
    "    def update(self, X, y, a, regime):\n",
    "        '''\n",
    "        Perform model update\n",
    "        X, y, a: torch.Tensor\n",
    "        '''\n",
    "        # update X, y, a\n",
    "        if self.X == None:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "            self.a = a\n",
    "        else:\n",
    "            self.X = torch.vstack((self.X, X))\n",
    "            self.y = torch.hstack((self.y, y))\n",
    "            self.a = torch.hstack((self.a, a))\n",
    "            \n",
    "        # update if enough data\n",
    "        if (len(self.a) >= self.N) and ((1 - self.a).sum() >= self.Na[0]) and (self.a.sum() >= self.Na[1]):\n",
    "            # perform training step\n",
    "            self.optimizer.zero_grad()\n",
    "            y_hat = self.model(self.X)\n",
    "            y_hat_1 = y_hat[self.a==1]\n",
    "            y_hat_0 = y_hat[self.a==0]\n",
    "            y_1 = self.y[self.a==1]\n",
    "            y_0 = self.y[self.a==0]\n",
    "            delta_1, delta_0 = 1, 1\n",
    "            N = len(self.a)\n",
    "            N_1 = self.a.sum()\n",
    "            N_0 = N-N_1\n",
    "            if N >= self.N:\n",
    "                if N_1 == 2:\n",
    "                    delta_1 = N/(2*(N-1))\n",
    "                    delta_0 = N/((N-1))\n",
    "                else:\n",
    "                    delta_1 = N/((N-1))\n",
    "                    delta_0 = N/(2*(N-1))\n",
    "            weight_1 = (delta_1) * N_1/N\n",
    "            weight_0 = (delta_0) * N_0/N\n",
    "            accloss1 = self.accloss(y_hat_1, y_1)\n",
    "            accloss0 = self.accloss(y_hat_0, y_0)\n",
    "            loss = (weight_0 * accloss0 + weight_1 * accloss1) + self.regularizer * self.fairloss(y_hat_1, y_hat_0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # reset data\n",
    "            self.X = None\n",
    "            self.y = None\n",
    "            self.a = None\n",
    "        \n",
    "        # perform tests\n",
    "        self.tester(self.model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ef0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, X, y1, y2, a, metrics):\n",
    "        self.X = X\n",
    "        self.y1 = y1\n",
    "        self.y2 = y2\n",
    "        self.a = a\n",
    "        \n",
    "        self.metrics = metrics\n",
    "        self.results = {k:[] for k in metrics.keys()}\n",
    "        self.MSEs = []\n",
    "        \n",
    "    def test(self, model, regime):\n",
    "        y = self.y1 if regime==1 else self.y2\n",
    "        y_hat = model(self.X)\n",
    "        MSE = ((y.flatten()-y_hat.flatten())**2).mean()\n",
    "        self.MSEs.append(MSE.detach().numpy()[()])\n",
    "        \n",
    "        \n",
    "        y_hat_1 = y_hat[self.a==1]\n",
    "        y_hat_0 = y_hat[self.a==0]\n",
    "        for m in self.metrics.keys():\n",
    "            self.results[m].append(self.metrics[m](y_hat_1, y_hat_0).detach().numpy()[()])\n",
    "        \n",
    "    def __call__(self, model, regime):\n",
    "        self.test(model, regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28bd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "N_iter = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1880c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes1 = 4*torch.rand((k, 5))-2\n",
    "slopes2 = 4*torch.rand((k, 5))-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192af2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.randint(10,(1,))==0).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_inverse=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc6d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(k, regime):\n",
    "    X = torch.rand((1,k-1))\n",
    "    a = (torch.randint(pa_inverse,(1,))==0).float()\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max()\n",
    "    y2 = (X @ slopes2).max()\n",
    "    if regime==1:\n",
    "        return X, y1, a\n",
    "    else:\n",
    "        return X, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_set(k, N_test=1000):\n",
    "    X = torch.rand((N_test,k-1))\n",
    "    a = (torch.randint(pa_inverse,(N_test,))==0).float()\n",
    "    X = torch.hstack((X,torch.unsqueeze(a, 1)))\n",
    "    y1 = (X @ slopes1).max(dim=1)[0]\n",
    "    y2 = (X @ slopes2).max(dim=1)[0]\n",
    "    return X, y1, y2, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f499ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, k):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(k, 20, bias=True)\n",
    "        self.linear2 = torch.nn.Linear(20, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        self.output = self.linear2(x)\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef359fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(yhat, y):\n",
    "    return ((yhat.flatten()-y.flatten())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'SPD': lambda y1, y2: fairness_metrics.statistical_parity(y1.flatten(), y2.flatten(), None, None),\n",
    "    'ED': fairness_metrics.energy_distance,\n",
    "    'WD': fairness_metrics.wasserstein_distance\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(N=4, seed=0):\n",
    "    test_set = build_test_set(k)\n",
    "    tester_ED_4 = Tester(*test_set, metrics)\n",
    "    tester_ED_fullbias_4 = Tester(*test_set, metrics)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_unbiased_4 = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance, 4, [2,2], tester_ED_4)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_bias_4 = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance_biased, 4, [2,2], tester_ED_fullbias_4)\n",
    "    \n",
    "    tester_ED_50 = Tester(*test_set, metrics)\n",
    "    tester_ED_fullbias_50 = Tester(*test_set, metrics)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_unbiased_50 = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance, 50, [2,2], tester_ED_50)\n",
    "    torch.manual_seed(seed)\n",
    "    trainer_ED_bias_50 = Trainer(NeuralNetwork(k), mse, fairness_metrics.energy_distance_biased, 50, [2,2], tester_ED_fullbias_50)\n",
    "    \n",
    "    regime = 1\n",
    "    for i in tqdm(range(N_iter)):\n",
    "        sample = get_sample(k, regime)\n",
    "        trainer_ED_unbiased_4.update(*sample, regime)\n",
    "        trainer_ED_bias_4.update(*sample, regime)\n",
    "        trainer_ED_unbiased_50.update(*sample, regime)\n",
    "        trainer_ED_bias_50.update(*sample, regime)\n",
    "        if i==N_iter/2:\n",
    "            regime = 2\n",
    "\n",
    "    return (trainer_ED_unbiased_4.tester, trainer_ED_bias_4.tester, trainer_ED_unbiased_50.tester, trainer_ED_bias_50.tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ub4s, b4s, ub50s, b50s = [], [], [], []\n",
    "for i in range(5):\n",
    "    ub4, b4, ub50, b50 = test(seed = i)\n",
    "    ub4s.append(ub4)\n",
    "    b4s.append(b4)\n",
    "    ub50s.append(ub50)\n",
    "    b50s.append(b50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe23604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecda030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.sans-serif'] = ['Times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc943e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daacd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dumps/slope1.npy', slopes1.numpy())\n",
    "np.save('dumps/slope2.npy', slopes2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb45bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in ub4s]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Unbiased MFL')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in b4s]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Biased MFL')\n",
    "\n",
    "plt.ylim(0.15,15)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Out-of-Sample Risk')\n",
    "plt.savefig('loss-comparison-bias-4.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64db4e6-6878-4170-ab11-1fc33a4f90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in ub50s]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Unbiased MFL')\n",
    "\n",
    "df = pd.melt(pd.DataFrame([np.array(tester.MSEs)+ 2*np.array(tester.results['ED']) for tester in b50s]).T.reset_index(), id_vars='index')\n",
    "df.columns = ['Time horizon', 'b', 'Loss']\n",
    "sns.lineplot(data = df, \n",
    "             x=\"Time horizon\", y=\"Loss\", label='Biased MFL')\n",
    "plt.ylim(0.15,15)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('Out-of-Sample Risk')\n",
    "plt.savefig('loss-comparison-bias-50.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a870b-fe89-4ced-acd2-35ba20011adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
